From 652ef5bcfce4b51ede84e3a4fa680155324f2a22 Mon Sep 17 00:00:00 2001
From: Matthew Waters <matthew@centricular.com>
Date: Wed, 28 Mar 2018 20:19:55 +1100
Subject: [PATCH] Rename accelarated aesni_* functions to not conflict with
 openssl

---
 lib/accelerated/x86/aes-cbc-x86-aesni.c      |  8 +--
 lib/accelerated/x86/aes-ccm-x86-aesni.c      |  4 +-
 lib/accelerated/x86/aes-gcm-x86-aesni.c      |  6 +-
 lib/accelerated/x86/aes-gcm-x86-pclmul-avx.c | 12 ++--
 lib/accelerated/x86/aes-gcm-x86-pclmul.c     | 12 ++--
 lib/accelerated/x86/aes-x86.h                | 10 +--
 lib/accelerated/x86/coff/aesni-x86_64.s      | 70 ++++++++++-----------
 lib/accelerated/x86/elf/aesni-x86.s          | 94 ++++++++++++++--------------
 lib/accelerated/x86/elf/aesni-x86_64.s       | 88 +++++++++++++-------------
 9 files changed, 152 insertions(+), 152 deletions(-)

diff --git a/lib/accelerated/x86/aes-cbc-x86-aesni.c b/lib/accelerated/x86/aes-cbc-x86-aesni.c
index 9b42cde..3c70b78 100644
--- a/lib/accelerated/x86/aes-cbc-x86-aesni.c
+++ b/lib/accelerated/x86/aes-cbc-x86-aesni.c
@@ -69,11 +69,11 @@ aes_cipher_setkey(void *_ctx, const void *userkey, size_t keysize)
 
 	if (ctx->enc)
 		ret =
-		    aesni_set_encrypt_key(userkey, keysize * 8,
+		    _aesni_set_encrypt_key(userkey, keysize * 8,
 					  ALIGN16(&ctx->expanded_key));
 	else
 		ret =
-		    aesni_set_decrypt_key(userkey, keysize * 8,
+		    _aesni_set_decrypt_key(userkey, keysize * 8,
 					  ALIGN16(&ctx->expanded_key));
 
 	if (ret != 0)
@@ -96,7 +96,7 @@ aes_encrypt(void *_ctx, const void *src, size_t src_size,
 {
 	struct aes_ctx *ctx = _ctx;
 
-	aesni_cbc_encrypt(src, dst, src_size, ALIGN16(&ctx->expanded_key),
+	_aesni_cbc_encrypt(src, dst, src_size, ALIGN16(&ctx->expanded_key),
 			  ctx->iv, 1);
 	return 0;
 }
@@ -107,7 +107,7 @@ aes_decrypt(void *_ctx, const void *src, size_t src_size,
 {
 	struct aes_ctx *ctx = _ctx;
 
-	aesni_cbc_encrypt(src, dst, src_size, ALIGN16(&ctx->expanded_key),
+	_aesni_cbc_encrypt(src, dst, src_size, ALIGN16(&ctx->expanded_key),
 			  ctx->iv, 0);
 
 	return 0;
diff --git a/lib/accelerated/x86/aes-ccm-x86-aesni.c b/lib/accelerated/x86/aes-ccm-x86-aesni.c
index 4828a22..69f0b3a 100644
--- a/lib/accelerated/x86/aes-ccm-x86-aesni.c
+++ b/lib/accelerated/x86/aes-ccm-x86-aesni.c
@@ -49,7 +49,7 @@ static void x86_aes_encrypt(const void *_ctx,
 			    const uint8_t * src)
 {
 	AES_KEY *ctx = (void*)_ctx;
-	aesni_ecb_encrypt(src, dst, length, ctx, 1);
+	_aesni_ecb_encrypt(src, dst, length, ctx, 1);
 }
 
 static int
@@ -76,7 +76,7 @@ static int
 aes_ccm_cipher_setkey(void *_ctx, const void *key, size_t length)
 {
 	struct ccm_x86_aes_ctx *ctx = _ctx;
-	aesni_set_encrypt_key(key, length*8, &ctx->key);
+	_aesni_set_encrypt_key(key, length*8, &ctx->key);
 
 	return 0;
 }
diff --git a/lib/accelerated/x86/aes-gcm-x86-aesni.c b/lib/accelerated/x86/aes-gcm-x86-aesni.c
index f361e70..c5869cd 100644
--- a/lib/accelerated/x86/aes-gcm-x86-aesni.c
+++ b/lib/accelerated/x86/aes-gcm-x86-aesni.c
@@ -49,7 +49,7 @@ static void x86_aes_encrypt(const void *_ctx,
 {
 	AES_KEY *ctx = (void*)_ctx;
 
-	aesni_ecb_encrypt(src, dst, length, ctx, 1);
+	_aesni_ecb_encrypt(src, dst, length, ctx, 1);
 }
 
 static void x86_aes128_set_encrypt_key(void *_ctx,
@@ -57,7 +57,7 @@ static void x86_aes128_set_encrypt_key(void *_ctx,
 {
 	AES_KEY *ctx = _ctx;
 
-	aesni_set_encrypt_key(key, 16*8, ctx);
+	_aesni_set_encrypt_key(key, 16*8, ctx);
 }
 
 static void x86_aes256_set_encrypt_key(void *_ctx,
@@ -65,7 +65,7 @@ static void x86_aes256_set_encrypt_key(void *_ctx,
 {
 	AES_KEY *ctx = _ctx;
 
-	aesni_set_encrypt_key(key, 32*8, ctx);
+	_aesni_set_encrypt_key(key, 32*8, ctx);
 }
 
 static int
diff --git a/lib/accelerated/x86/aes-gcm-x86-pclmul-avx.c b/lib/accelerated/x86/aes-gcm-x86-pclmul-avx.c
index 59cb7e8..287d4ec 100644
--- a/lib/accelerated/x86/aes-gcm-x86-pclmul-avx.c
+++ b/lib/accelerated/x86/aes-gcm-x86-pclmul-avx.c
@@ -100,12 +100,12 @@ aes_gcm_cipher_setkey(void *_ctx, const void *userkey, size_t keysize)
 	CHECK_AES_KEYSIZE(keysize);
 
 	ret =
-	    aesni_set_encrypt_key(userkey, keysize * 8,
+	    _aesni_set_encrypt_key(userkey, keysize * 8,
 				  ALIGN16(&ctx->expanded_key));
 	if (ret != 0)
 		return gnutls_assert_val(GNUTLS_E_ENCRYPTION_FAILED);
 
-	aesni_ecb_encrypt(ctx->gcm.H.c, ctx->gcm.H.c,
+	_aesni_ecb_encrypt(ctx->gcm.H.c, ctx->gcm.H.c,
 			  GCM_BLOCK_SIZE, ALIGN16(&ctx->expanded_key), 1);
 
 	ctx->gcm.H.u[0] = bswap_64(ctx->gcm.H.u[0]);
@@ -132,7 +132,7 @@ static int aes_gcm_setiv(void *_ctx, const void *iv, size_t iv_size)
 	ctx->gcm.Yi.c[GCM_BLOCK_SIZE - 2] = 0;
 	ctx->gcm.Yi.c[GCM_BLOCK_SIZE - 1] = 1;
 
-	aesni_ecb_encrypt(ctx->gcm.Yi.c, ctx->gcm.EK0.c,
+	_aesni_ecb_encrypt(ctx->gcm.Yi.c, ctx->gcm.EK0.c,
 			  GCM_BLOCK_SIZE, ALIGN16(&ctx->expanded_key), 1);
 	ctx->gcm.Yi.c[GCM_BLOCK_SIZE - 1] = 2;
 	return 0;
@@ -162,7 +162,7 @@ ctr_encrypt_last(struct aes_gcm_ctx *ctx, const uint8_t * src,
 	uint8_t out[GCM_BLOCK_SIZE];
 
 	memcpy(tmp, &src[pos], length);
-	aesni_ctr32_encrypt_blocks(tmp, out, 1,
+	_aesni_ctr32_encrypt_blocks(tmp, out, 1,
 				   ALIGN16(&ctx->expanded_key),
 				   ctx->gcm.Yi.c);
 
@@ -181,7 +181,7 @@ aes_gcm_encrypt(void *_ctx, const void *src, size_t src_size,
 	uint32_t counter;
 
 	if (blocks > 0) {
-		aesni_ctr32_encrypt_blocks(src, dst,
+		_aesni_ctr32_encrypt_blocks(src, dst,
 					   blocks,
 					   ALIGN16(&ctx->expanded_key),
 					   ctx->gcm.Yi.c);
@@ -214,7 +214,7 @@ aes_gcm_decrypt(void *_ctx, const void *src, size_t src_size,
 	ctx->gcm.len.u[1] += src_size;
 
 	if (blocks > 0) {
-		aesni_ctr32_encrypt_blocks(src, dst,
+		_aesni_ctr32_encrypt_blocks(src, dst,
 					   blocks,
 					   ALIGN16(&ctx->expanded_key),
 					   ctx->gcm.Yi.c);
diff --git a/lib/accelerated/x86/aes-gcm-x86-pclmul.c b/lib/accelerated/x86/aes-gcm-x86-pclmul.c
index 4411e54..3db86a6 100644
--- a/lib/accelerated/x86/aes-gcm-x86-pclmul.c
+++ b/lib/accelerated/x86/aes-gcm-x86-pclmul.c
@@ -99,12 +99,12 @@ aes_gcm_cipher_setkey(void *_ctx, const void *userkey, size_t keysize)
 	CHECK_AES_KEYSIZE(keysize);
 
 	ret =
-	    aesni_set_encrypt_key(userkey, keysize * 8,
+	    _aesni_set_encrypt_key(userkey, keysize * 8,
 				  ALIGN16(&ctx->expanded_key));
 	if (ret != 0)
 		return gnutls_assert_val(GNUTLS_E_ENCRYPTION_FAILED);
 
-	aesni_ecb_encrypt(ctx->gcm.H.c, ctx->gcm.H.c,
+	_aesni_ecb_encrypt(ctx->gcm.H.c, ctx->gcm.H.c,
 			  GCM_BLOCK_SIZE, ALIGN16(&ctx->expanded_key), 1);
 
 	ctx->gcm.H.u[0] = bswap_64(ctx->gcm.H.u[0]);
@@ -131,7 +131,7 @@ static int aes_gcm_setiv(void *_ctx, const void *iv, size_t iv_size)
 	ctx->gcm.Yi.c[GCM_BLOCK_SIZE - 2] = 0;
 	ctx->gcm.Yi.c[GCM_BLOCK_SIZE - 1] = 1;
 
-	aesni_ecb_encrypt(ctx->gcm.Yi.c, ctx->gcm.EK0.c,
+	_aesni_ecb_encrypt(ctx->gcm.Yi.c, ctx->gcm.EK0.c,
 			  GCM_BLOCK_SIZE, ALIGN16(&ctx->expanded_key), 1);
 	ctx->gcm.Yi.c[GCM_BLOCK_SIZE - 1] = 2;
 	return 0;
@@ -161,7 +161,7 @@ ctr_encrypt_last(struct aes_gcm_ctx *ctx, const uint8_t * src,
 	uint8_t out[GCM_BLOCK_SIZE];
 
 	memcpy(tmp, &src[pos], length);
-	aesni_ctr32_encrypt_blocks(tmp, out, 1,
+	_aesni_ctr32_encrypt_blocks(tmp, out, 1,
 				   ALIGN16(&ctx->expanded_key),
 				   ctx->gcm.Yi.c);
 
@@ -180,7 +180,7 @@ aes_gcm_encrypt(void *_ctx, const void *src, size_t src_size,
 	uint32_t counter;
 
 	if (blocks > 0) {
-		aesni_ctr32_encrypt_blocks(src, dst,
+		_aesni_ctr32_encrypt_blocks(src, dst,
 					   blocks,
 					   ALIGN16(&ctx->expanded_key),
 					   ctx->gcm.Yi.c);
@@ -213,7 +213,7 @@ aes_gcm_decrypt(void *_ctx, const void *src, size_t src_size,
 	ctx->gcm.len.u[1] += src_size;
 
 	if (blocks > 0) {
-		aesni_ctr32_encrypt_blocks(src, dst,
+		_aesni_ctr32_encrypt_blocks(src, dst,
 					   blocks,
 					   ALIGN16(&ctx->expanded_key),
 					   ctx->gcm.Yi.c);
diff --git a/lib/accelerated/x86/aes-x86.h b/lib/accelerated/x86/aes-x86.h
index 2fcd890..afb46d2 100644
--- a/lib/accelerated/x86/aes-x86.h
+++ b/lib/accelerated/x86/aes-x86.h
@@ -22,18 +22,18 @@ typedef struct {
 	if (s != 16 && s != 24 && s != 32) \
 		return GNUTLS_E_INVALID_REQUEST
 
-void aesni_ecb_encrypt(const unsigned char *in, unsigned char *out,
+void _aesni_ecb_encrypt(const unsigned char *in, unsigned char *out,
 		       size_t len, const AES_KEY * key, int enc);
 
-void aesni_cbc_encrypt(const unsigned char *in, unsigned char *out,
+void _aesni_cbc_encrypt(const unsigned char *in, unsigned char *out,
 		       size_t len, const AES_KEY * key,
 		       unsigned char *ivec, const int enc);
-int aesni_set_decrypt_key(const unsigned char *userKey, const int bits,
+int _aesni_set_decrypt_key(const unsigned char *userKey, const int bits,
 			  AES_KEY * key);
-int aesni_set_encrypt_key(const unsigned char *userKey, const int bits,
+int _aesni_set_encrypt_key(const unsigned char *userKey, const int bits,
 			  AES_KEY * key);
 
-void aesni_ctr32_encrypt_blocks(const unsigned char *in,
+void _aesni_ctr32_encrypt_blocks(const unsigned char *in,
 				unsigned char *out,
 				size_t blocks,
 				const void *key,
diff --git a/lib/accelerated/x86/coff/aesni-x86_64.s b/lib/accelerated/x86/coff/aesni-x86_64.s
index 79ffbf7..85773f8 100644
--- a/lib/accelerated/x86/coff/aesni-x86_64.s
+++ b/lib/accelerated/x86/coff/aesni-x86_64.s
@@ -39,10 +39,10 @@
 #
 .text	
 
-.globl	aesni_encrypt
-.def	aesni_encrypt;	.scl 2;	.type 32;	.endef
+.globl	_aesni_encrypt
+.def	_aesni_encrypt;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_encrypt:
+_aesni_encrypt:
 	movups	(%rcx),%xmm2
 	movl	240(%r8),%eax
 	movups	(%r8),%xmm0
@@ -63,10 +63,10 @@ aesni_encrypt:
 	.byte	0xf3,0xc3
 
 
-.globl	aesni_decrypt
-.def	aesni_decrypt;	.scl 2;	.type 32;	.endef
+.globl	_aesni_decrypt
+.def	_aesni_decrypt;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_decrypt:
+_aesni_decrypt:
 	movups	(%rcx),%xmm2
 	movl	240(%r8),%eax
 	movups	(%r8),%xmm0
@@ -528,10 +528,10 @@ _aesni_decrypt8:
 .byte	102,68,15,56,223,200
 	.byte	0xf3,0xc3
 
-.globl	aesni_ecb_encrypt
-.def	aesni_ecb_encrypt;	.scl 2;	.type 32;	.endef
+.globl	_aesni_ecb_encrypt
+.def	_aesni_ecb_encrypt;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_ecb_encrypt:
+_aesni_ecb_encrypt:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -898,10 +898,10 @@ aesni_ecb_encrypt:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_ecb_encrypt:
-.globl	aesni_ccm64_encrypt_blocks
-.def	aesni_ccm64_encrypt_blocks;	.scl 2;	.type 32;	.endef
+.globl	_aesni_ccm64_encrypt_blocks
+.def	_aesni_ccm64_encrypt_blocks;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_ccm64_encrypt_blocks:
+_aesni_ccm64_encrypt_blocks:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -990,10 +990,10 @@ aesni_ccm64_encrypt_blocks:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_ccm64_encrypt_blocks:
-.globl	aesni_ccm64_decrypt_blocks
-.def	aesni_ccm64_decrypt_blocks;	.scl 2;	.type 32;	.endef
+.globl	_aesni_ccm64_decrypt_blocks
+.def	_aesni_ccm64_decrypt_blocks;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_ccm64_decrypt_blocks:
+_aesni_ccm64_decrypt_blocks:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -1116,10 +1116,10 @@ aesni_ccm64_decrypt_blocks:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_ccm64_decrypt_blocks:
-.globl	aesni_ctr32_encrypt_blocks
-.def	aesni_ctr32_encrypt_blocks;	.scl 2;	.type 32;	.endef
+.globl	_aesni_ctr32_encrypt_blocks
+.def	_aesni_ctr32_encrypt_blocks;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_ctr32_encrypt_blocks:
+_aesni_ctr32_encrypt_blocks:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -1722,10 +1722,10 @@ aesni_ctr32_encrypt_blocks:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_ctr32_encrypt_blocks:
-.globl	aesni_xts_encrypt
-.def	aesni_xts_encrypt;	.scl 2;	.type 32;	.endef
+.globl	_aesni_xts_encrypt
+.def	_aesni_xts_encrypt;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_xts_encrypt:
+_aesni_xts_encrypt:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -2221,10 +2221,10 @@ aesni_xts_encrypt:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_xts_encrypt:
-.globl	aesni_xts_decrypt
-.def	aesni_xts_decrypt;	.scl 2;	.type 32;	.endef
+.globl	_aesni_xts_decrypt
+.def	_aesni_xts_decrypt;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_xts_decrypt:
+_aesni_xts_decrypt:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -2757,10 +2757,10 @@ aesni_xts_decrypt:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_xts_decrypt:
-.globl	aesni_cbc_encrypt
-.def	aesni_cbc_encrypt;	.scl 2;	.type 32;	.endef
+.globl	_aesni_cbc_encrypt
+.def	_aesni_cbc_encrypt;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_cbc_encrypt:
+_aesni_cbc_encrypt:
 	movq	%rdi,8(%rsp)
 	movq	%rsi,16(%rsp)
 	movq	%rsp,%rax
@@ -3382,10 +3382,10 @@ aesni_cbc_encrypt:
 	movq	16(%rsp),%rsi
 	.byte	0xf3,0xc3
 .LSEH_end_aesni_cbc_encrypt:
-.globl	aesni_set_decrypt_key
-.def	aesni_set_decrypt_key;	.scl 2;	.type 32;	.endef
+.globl	_aesni_set_decrypt_key
+.def	_aesni_set_decrypt_key;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_set_decrypt_key:
+_aesni_set_decrypt_key:
 .byte	0x48,0x83,0xEC,0x08
 	call	__aesni_set_encrypt_key
 	shll	$4,%edx
@@ -3422,10 +3422,10 @@ aesni_set_decrypt_key:
 	.byte	0xf3,0xc3
 .LSEH_end_set_decrypt_key:
 
-.globl	aesni_set_encrypt_key
-.def	aesni_set_encrypt_key;	.scl 2;	.type 32;	.endef
+.globl	_aesni_set_encrypt_key
+.def	_aesni_set_encrypt_key;	.scl 2;	.type 32;	.endef
 .p2align	4
-aesni_set_encrypt_key:
+_aesni_set_encrypt_key:
 __aesni_set_encrypt_key:
 .byte	0x48,0x83,0xEC,0x08
 	movq	$-1,%rax
@@ -4010,11 +4010,11 @@ cbc_se_handler:
 .rva	.LSEH_end_aesni_cbc_encrypt
 .rva	.LSEH_info_cbc
 
-.rva	aesni_set_decrypt_key
+.rva	_aesni_set_decrypt_key
 .rva	.LSEH_end_set_decrypt_key
 .rva	.LSEH_info_key
 
-.rva	aesni_set_encrypt_key
+.rva	_aesni_set_encrypt_key
 .rva	.LSEH_end_set_encrypt_key
 .rva	.LSEH_info_key
 .section	.xdata
diff --git a/lib/accelerated/x86/elf/aesni-x86.s b/lib/accelerated/x86/elf/aesni-x86.s
index 5d70f25..1032802 100644
--- a/lib/accelerated/x86/elf/aesni-x86.s
+++ b/lib/accelerated/x86/elf/aesni-x86.s
@@ -39,10 +39,10 @@
 #
 .file	"devel/perlasm/aesni-x86.s"
 .text
-.globl	aesni_encrypt
-.type	aesni_encrypt,@function
+.globl	_aesni_encrypt
+.type	_aesni_encrypt,@function
 .align	16
-aesni_encrypt:
+_aesni_encrypt:
 .L_aesni_encrypt_begin:
 	movl	4(%esp),%eax
 	movl	12(%esp),%edx
@@ -62,11 +62,11 @@ aesni_encrypt:
 .byte	102,15,56,221,209
 	movups	%xmm2,(%eax)
 	ret
-.size	aesni_encrypt,.-.L_aesni_encrypt_begin
-.globl	aesni_decrypt
-.type	aesni_decrypt,@function
+.size	_aesni_encrypt,.-.L_aesni_encrypt_begin
+.globl	_aesni_decrypt
+.type	_aesni_decrypt,@function
 .align	16
-aesni_decrypt:
+_aesni_decrypt:
 .L_aesni_decrypt_begin:
 	movl	4(%esp),%eax
 	movl	12(%esp),%edx
@@ -86,7 +86,7 @@ aesni_decrypt:
 .byte	102,15,56,223,209
 	movups	%xmm2,(%eax)
 	ret
-.size	aesni_decrypt,.-.L_aesni_decrypt_begin
+.size	_aesni_decrypt,.-.L_aesni_decrypt_begin
 .type	_aesni_encrypt3,@function
 .align	16
 _aesni_encrypt3:
@@ -335,10 +335,10 @@ _aesni_decrypt6:
 .byte	102,15,56,223,248
 	ret
 .size	_aesni_decrypt6,.-_aesni_decrypt6
-.globl	aesni_ecb_encrypt
-.type	aesni_ecb_encrypt,@function
+.globl	_aesni_ecb_encrypt
+.type	_aesni_ecb_encrypt,@function
 .align	16
-aesni_ecb_encrypt:
+_aesni_ecb_encrypt:
 .L_aesni_ecb_encrypt_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -563,11 +563,11 @@ aesni_ecb_encrypt:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_ecb_encrypt,.-.L_aesni_ecb_encrypt_begin
-.globl	aesni_ccm64_encrypt_blocks
-.type	aesni_ccm64_encrypt_blocks,@function
+.size	_aesni_ecb_encrypt,.-.L_aesni_ecb_encrypt_begin
+.globl	_aesni_ccm64_encrypt_blocks
+.type	_aesni_ccm64_encrypt_blocks,@function
 .align	16
-aesni_ccm64_encrypt_blocks:
+_aesni_ccm64_encrypt_blocks:
 .L_aesni_ccm64_encrypt_blocks_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -643,11 +643,11 @@ aesni_ccm64_encrypt_blocks:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_ccm64_encrypt_blocks,.-.L_aesni_ccm64_encrypt_blocks_begin
-.globl	aesni_ccm64_decrypt_blocks
-.type	aesni_ccm64_decrypt_blocks,@function
+.size	_aesni_ccm64_encrypt_blocks,.-.L_aesni_ccm64_encrypt_blocks_begin
+.globl	_aesni_ccm64_decrypt_blocks
+.type	_aesni_ccm64_decrypt_blocks,@function
 .align	16
-aesni_ccm64_decrypt_blocks:
+_aesni_ccm64_decrypt_blocks:
 .L_aesni_ccm64_decrypt_blocks_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -755,11 +755,11 @@ aesni_ccm64_decrypt_blocks:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_ccm64_decrypt_blocks,.-.L_aesni_ccm64_decrypt_blocks_begin
-.globl	aesni_ctr32_encrypt_blocks
-.type	aesni_ctr32_encrypt_blocks,@function
+.size	_aesni_ccm64_decrypt_blocks,.-.L_aesni_ccm64_decrypt_blocks_begin
+.globl	_aesni_ctr32_encrypt_blocks
+.type	_aesni_ctr32_encrypt_blocks,@function
 .align	16
-aesni_ctr32_encrypt_blocks:
+_aesni_ctr32_encrypt_blocks:
 .L_aesni_ctr32_encrypt_blocks_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -986,11 +986,11 @@ aesni_ctr32_encrypt_blocks:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_ctr32_encrypt_blocks,.-.L_aesni_ctr32_encrypt_blocks_begin
-.globl	aesni_xts_encrypt
-.type	aesni_xts_encrypt,@function
+.size	_aesni_ctr32_encrypt_blocks,.-.L_aesni_ctr32_encrypt_blocks_begin
+.globl	_aesni_xts_encrypt
+.type	_aesni_xts_encrypt,@function
 .align	16
-aesni_xts_encrypt:
+_aesni_xts_encrypt:
 .L_aesni_xts_encrypt_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -1333,11 +1333,11 @@ aesni_xts_encrypt:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_xts_encrypt,.-.L_aesni_xts_encrypt_begin
-.globl	aesni_xts_decrypt
-.type	aesni_xts_decrypt,@function
+.size	_aesni_xts_encrypt,.-.L_aesni_xts_encrypt_begin
+.globl	_aesni_xts_decrypt
+.type	_aesni_xts_decrypt,@function
 .align	16
-aesni_xts_decrypt:
+_aesni_xts_decrypt:
 .L_aesni_xts_decrypt_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -1709,11 +1709,11 @@ aesni_xts_decrypt:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_xts_decrypt,.-.L_aesni_xts_decrypt_begin
-.globl	aesni_cbc_encrypt
-.type	aesni_cbc_encrypt,@function
+.size	_aesni_xts_decrypt,.-.L_aesni_xts_decrypt_begin
+.globl	_aesni_cbc_encrypt
+.type	_aesni_cbc_encrypt,@function
 .align	16
-aesni_cbc_encrypt:
+_aesni_cbc_encrypt:
 .L_aesni_cbc_encrypt_begin:
 	pushl	%ebp
 	pushl	%ebx
@@ -1947,10 +1947,10 @@ aesni_cbc_encrypt:
 	popl	%ebx
 	popl	%ebp
 	ret
-.size	aesni_cbc_encrypt,.-.L_aesni_cbc_encrypt_begin
-.type	_aesni_set_encrypt_key,@function
+.size	_aesni_cbc_encrypt,.-.L_aesni_cbc_encrypt_begin
+.type	__aesni_set_encrypt_key,@function
 .align	16
-_aesni_set_encrypt_key:
+__aesni_set_encrypt_key:
 	testl	%eax,%eax
 	jz	.L086bad_pointer
 	testl	%edx,%edx
@@ -2126,22 +2126,22 @@ _aesni_set_encrypt_key:
 .L089bad_keybits:
 	movl	$-2,%eax
 	ret
-.size	_aesni_set_encrypt_key,.-_aesni_set_encrypt_key
-.globl	aesni_set_encrypt_key
-.type	aesni_set_encrypt_key,@function
+.size	__aesni_set_encrypt_key,.-__aesni_set_encrypt_key
+.globl	_aesni_set_encrypt_key
+.type	_aesni_set_encrypt_key,@function
 .align	16
-aesni_set_encrypt_key:
+_aesni_set_encrypt_key:
 .L_aesni_set_encrypt_key_begin:
 	movl	4(%esp),%eax
 	movl	8(%esp),%ecx
 	movl	12(%esp),%edx
 	call	_aesni_set_encrypt_key
 	ret
-.size	aesni_set_encrypt_key,.-.L_aesni_set_encrypt_key_begin
-.globl	aesni_set_decrypt_key
-.type	aesni_set_decrypt_key,@function
+.size	_aesni_set_encrypt_key,.-.L_aesni_set_encrypt_key_begin
+.globl	_aesni_set_decrypt_key
+.type	_aesni_set_decrypt_key,@function
 .align	16
-aesni_set_decrypt_key:
+_aesni_set_decrypt_key:
 .L_aesni_set_decrypt_key_begin:
 	movl	4(%esp),%eax
 	movl	8(%esp),%ecx
@@ -2175,7 +2175,7 @@ aesni_set_decrypt_key:
 	xorl	%eax,%eax
 .L100dec_key_ret:
 	ret
-.size	aesni_set_decrypt_key,.-.L_aesni_set_decrypt_key_begin
+.size	_aesni_set_decrypt_key,.-.L_aesni_set_decrypt_key_begin
 .byte	65,69,83,32,102,111,114,32,73,110,116,101,108,32,65,69
 .byte	83,45,78,73,44,32,67,82,89,80,84,79,71,65,77,83
 .byte	32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115
diff --git a/lib/accelerated/x86/elf/aesni-x86_64.s b/lib/accelerated/x86/elf/aesni-x86_64.s
index 76d44fc..458d7fc 100644
--- a/lib/accelerated/x86/elf/aesni-x86_64.s
+++ b/lib/accelerated/x86/elf/aesni-x86_64.s
@@ -39,10 +39,10 @@
 #
 .text	
 
-.globl	aesni_encrypt
-.type	aesni_encrypt,@function
+.globl	_aesni_encrypt
+.type	_aesni_encrypt,@function
 .align	16
-aesni_encrypt:
+_aesni_encrypt:
 	movups	(%rdi),%xmm2
 	movl	240(%rdx),%eax
 	movups	(%rdx),%xmm0
@@ -61,12 +61,12 @@ aesni_encrypt:
 	movups	%xmm2,(%rsi)
 	pxor	%xmm2,%xmm2
 	.byte	0xf3,0xc3
-.size	aesni_encrypt,.-aesni_encrypt
+.size	_aesni_encrypt,.-_aesni_encrypt
 
-.globl	aesni_decrypt
-.type	aesni_decrypt,@function
+.globl	_aesni_decrypt
+.type	_aesni_decrypt,@function
 .align	16
-aesni_decrypt:
+_aesni_decrypt:
 	movups	(%rdi),%xmm2
 	movl	240(%rdx),%eax
 	movups	(%rdx),%xmm0
@@ -85,7 +85,7 @@ aesni_decrypt:
 	movups	%xmm2,(%rsi)
 	pxor	%xmm2,%xmm2
 	.byte	0xf3,0xc3
-.size	aesni_decrypt, .-aesni_decrypt
+.size	_aesni_decrypt, .-_aesni_decrypt
 .type	_aesni_encrypt2,@function
 .align	16
 _aesni_encrypt2:
@@ -528,10 +528,10 @@ _aesni_decrypt8:
 .byte	102,68,15,56,223,200
 	.byte	0xf3,0xc3
 .size	_aesni_decrypt8,.-_aesni_decrypt8
-.globl	aesni_ecb_encrypt
-.type	aesni_ecb_encrypt,@function
+.globl	_aesni_ecb_encrypt
+.type	_aesni_ecb_encrypt,@function
 .align	16
-aesni_ecb_encrypt:
+_aesni_ecb_encrypt:
 	andq	$-16,%rdx
 	jz	.Lecb_ret
 
@@ -869,11 +869,11 @@ aesni_ecb_encrypt:
 	xorps	%xmm0,%xmm0
 	pxor	%xmm1,%xmm1
 	.byte	0xf3,0xc3
-.size	aesni_ecb_encrypt,.-aesni_ecb_encrypt
-.globl	aesni_ccm64_encrypt_blocks
-.type	aesni_ccm64_encrypt_blocks,@function
+.size	_aesni_ecb_encrypt,.-_aesni_ecb_encrypt
+.globl	_aesni_ccm64_encrypt_blocks
+.type	_aesni_ccm64_encrypt_blocks,@function
 .align	16
-aesni_ccm64_encrypt_blocks:
+_aesni_ccm64_encrypt_blocks:
 	movl	240(%rcx),%eax
 	movdqu	(%r8),%xmm6
 	movdqa	.Lincrement64(%rip),%xmm9
@@ -932,11 +932,11 @@ aesni_ccm64_encrypt_blocks:
 	pxor	%xmm8,%xmm8
 	pxor	%xmm6,%xmm6
 	.byte	0xf3,0xc3
-.size	aesni_ccm64_encrypt_blocks,.-aesni_ccm64_encrypt_blocks
-.globl	aesni_ccm64_decrypt_blocks
-.type	aesni_ccm64_decrypt_blocks,@function
+.size	_aesni_ccm64_encrypt_blocks,.-_aesni_ccm64_encrypt_blocks
+.globl	_aesni_ccm64_decrypt_blocks
+.type	_aesni_ccm64_decrypt_blocks,@function
 .align	16
-aesni_ccm64_decrypt_blocks:
+_aesni_ccm64_decrypt_blocks:
 	movl	240(%rcx),%eax
 	movups	(%r8),%xmm6
 	movdqu	(%r9),%xmm3
@@ -1029,11 +1029,11 @@ aesni_ccm64_decrypt_blocks:
 	pxor	%xmm8,%xmm8
 	pxor	%xmm6,%xmm6
 	.byte	0xf3,0xc3
-.size	aesni_ccm64_decrypt_blocks,.-aesni_ccm64_decrypt_blocks
-.globl	aesni_ctr32_encrypt_blocks
-.type	aesni_ctr32_encrypt_blocks,@function
+.size	_aesni_ccm64_decrypt_blocks,.-_aesni_ccm64_decrypt_blocks
+.globl	_aesni_ctr32_encrypt_blocks
+.type	_aesni_ctr32_encrypt_blocks,@function
 .align	16
-aesni_ctr32_encrypt_blocks:
+_aesni_ctr32_encrypt_blocks:
 	cmpq	$1,%rdx
 	jne	.Lctr32_bulk
 
@@ -1602,11 +1602,11 @@ aesni_ctr32_encrypt_blocks:
 	popq	%rbp
 .Lctr32_epilogue:
 	.byte	0xf3,0xc3
-.size	aesni_ctr32_encrypt_blocks,.-aesni_ctr32_encrypt_blocks
-.globl	aesni_xts_encrypt
-.type	aesni_xts_encrypt,@function
+.size	_aesni_ctr32_encrypt_blocks,.-_aesni_ctr32_encrypt_blocks
+.globl	_aesni_xts_encrypt
+.type	_aesni_xts_encrypt,@function
 .align	16
-aesni_xts_encrypt:
+_aesni_xts_encrypt:
 	leaq	(%rsp),%rax
 	pushq	%rbp
 	subq	$112,%rsp
@@ -2067,11 +2067,11 @@ aesni_xts_encrypt:
 	popq	%rbp
 .Lxts_enc_epilogue:
 	.byte	0xf3,0xc3
-.size	aesni_xts_encrypt,.-aesni_xts_encrypt
-.globl	aesni_xts_decrypt
-.type	aesni_xts_decrypt,@function
+.size	_aesni_xts_encrypt,.-_aesni_xts_encrypt
+.globl	_aesni_xts_decrypt
+.type	_aesni_xts_decrypt,@function
 .align	16
-aesni_xts_decrypt:
+_aesni_xts_decrypt:
 	leaq	(%rsp),%rax
 	pushq	%rbp
 	subq	$112,%rsp
@@ -2569,11 +2569,11 @@ aesni_xts_decrypt:
 	popq	%rbp
 .Lxts_dec_epilogue:
 	.byte	0xf3,0xc3
-.size	aesni_xts_decrypt,.-aesni_xts_decrypt
-.globl	aesni_cbc_encrypt
-.type	aesni_cbc_encrypt,@function
+.size	_aesni_xts_decrypt,.-_aesni_xts_decrypt
+.globl	_aesni_cbc_encrypt
+.type	_aesni_cbc_encrypt,@function
 .align	16
-aesni_cbc_encrypt:
+_aesni_cbc_encrypt:
 	testq	%rdx,%rdx
 	jz	.Lcbc_ret
 
@@ -3154,11 +3154,11 @@ aesni_cbc_encrypt:
 	popq	%rbp
 .Lcbc_ret:
 	.byte	0xf3,0xc3
-.size	aesni_cbc_encrypt,.-aesni_cbc_encrypt
-.globl	aesni_set_decrypt_key
-.type	aesni_set_decrypt_key,@function
+.size	_aesni_cbc_encrypt,.-_aesni_cbc_encrypt
+.globl	_aesni_set_decrypt_key
+.type	_aesni_set_decrypt_key,@function
 .align	16
-aesni_set_decrypt_key:
+_aesni_set_decrypt_key:
 .byte	0x48,0x83,0xEC,0x08
 	call	__aesni_set_encrypt_key
 	shll	$4,%esi
@@ -3194,11 +3194,11 @@ aesni_set_decrypt_key:
 	addq	$8,%rsp
 	.byte	0xf3,0xc3
 .LSEH_end_set_decrypt_key:
-.size	aesni_set_decrypt_key,.-aesni_set_decrypt_key
-.globl	aesni_set_encrypt_key
-.type	aesni_set_encrypt_key,@function
+.size	_aesni_set_decrypt_key,.-_aesni_set_decrypt_key
+.globl	_aesni_set_encrypt_key
+.type	_aesni_set_encrypt_key,@function
 .align	16
-aesni_set_encrypt_key:
+_aesni_set_encrypt_key:
 __aesni_set_encrypt_key:
 .byte	0x48,0x83,0xEC,0x08
 	movq	$-1,%rax
@@ -3564,7 +3564,7 @@ __aesni_set_encrypt_key:
 	shufps	$170,%xmm1,%xmm1
 	xorps	%xmm1,%xmm2
 	.byte	0xf3,0xc3
-.size	aesni_set_encrypt_key,.-aesni_set_encrypt_key
+.size	_aesni_set_encrypt_key,.-_aesni_set_encrypt_key
 .size	__aesni_set_encrypt_key,.-__aesni_set_encrypt_key
 .align	64
 .Lbswap_mask:
-- 
2.16.2

